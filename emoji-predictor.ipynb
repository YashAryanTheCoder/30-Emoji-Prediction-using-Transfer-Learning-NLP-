{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "emoji_dictionary={\n",
    "    \"0\": \"\\u2764\\uFE0F\",\n",
    "    \"1\": \":baseball:\",\n",
    "    \"2\": \":grinning_face_with_big_eyes:\",\n",
    "    \"3\": \":disappointed_face:\",\n",
    "    \"4\": \":fork_and_knife:\",\n",
    "    \"5\": \":hundred_points:\",\n",
    "    \"6\": \":fire:\",\n",
    "    \"7\": \":face_blowing_a_kiss:\",\n",
    "    \"8\": \":chestnut:\",\n",
    "    \"9\": \":flexed_biceps:\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('dataset/train_emoji.csv',header=None)\n",
    "test=pd.read_csv('dataset/test_emoji.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 4)\n"
     ]
    }
   ],
   "source": [
    "data=train.values\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train[0]\n",
    "Y_train=train[1]\n",
    "\n",
    "X_test=test[0]\n",
    "Y_test=test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÉ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(X_train[i],emoji.emojize(emoji_dictionary[str(Y_train[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('glove.6B.50d.txt',encoding='utf-8')\n",
    "embeddings_index={}\n",
    "cnt=0\n",
    "for line in f:\n",
    "    values=line.split()\n",
    "    word=values[0]\n",
    "    coefs=np.asarray(values[1:],dtype='float')\n",
    "    embeddings_index[word]=coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.4295e-01, -4.2946e-01, -5.4277e-01, -1.0307e+00,  1.2056e+00,\n",
       "       -2.7174e-01, -6.3561e-01, -1.5065e-02,  3.7856e-01,  4.6474e-02,\n",
       "       -1.3102e-01,  6.0500e-01,  1.6391e+00,  2.3940e-01,  1.2128e+00,\n",
       "        8.3178e-01,  7.3893e-01,  1.5200e-01, -1.4175e-01, -8.8384e-01,\n",
       "        2.0829e-02, -3.2545e-01,  1.8035e+00,  1.0045e+00,  5.8484e-01,\n",
       "       -6.2031e-01, -4.3296e-01,  2.3562e-01,  1.3027e+00, -8.1264e-01,\n",
       "        2.3158e+00,  1.1030e+00, -6.0608e-01,  1.0101e+00, -2.2426e-01,\n",
       "        1.8908e-02, -1.0931e-01,  3.8350e-01,  7.7362e-01, -8.1927e-02,\n",
       "       -3.4040e-01, -1.5143e-03, -5.6640e-02,  8.7359e-01,  1.4805e+00,\n",
       "        6.9421e-01, -3.0966e-01, -9.0826e-01,  3.7277e-03,  8.4550e-01])"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"eat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "emb_dim=embeddings_index[\"eat\"].shape[0]\n",
    "print(emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_output(X):\n",
    "    maxLen=10\n",
    "    embedding_out=np.zeros((X.shape[0],maxLen,emb_dim))\n",
    "    for ix in range(X.shape[0]):\n",
    "        X[ix]=X[ix].split()\n",
    "        for ij in range(len(X[ix])):\n",
    "            try:\n",
    "                embedding_out[ix][ij]=embeddings_index[X[ix][ij].lower()]\n",
    "            except:\n",
    "                embedding_out[ix][ij]=np.zeros((50,))\n",
    "    return embedding_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash Aryan\\AppData\\Local\\Temp\\ipykernel_12896\\3145651930.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[ix]=X[ix].split()\n"
     ]
    }
   ],
   "source": [
    "embeddings_matrix_train=embedding_output(X_train)\n",
    "embeddings_matrix_test=embedding_output(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 10, 50)\n",
      "(56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_matrix_train.shape)\n",
    "print(embeddings_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 5)\n",
      "[0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y_train=to_categorical(Y_train,num_classes=5)\n",
    "Y_test=to_categorical(Y_test,num_classes=5)\n",
    "print(Y_train.shape)\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 10, 64)            29440     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 10, 64)            0         \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "model=Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='cetegorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint=ModelCheckpoint(\"best_model.h5\",monitor='val_loss',verbose=True,save_best_only=True)\n",
    "earlystop=EarlyStopping(monitor='val_acc',patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 7s 1s/step - loss: 1.6069 - accuracy: 0.1827 - val_loss: 1.6094 - val_accuracy: 0.2222\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.5714 - accuracy: 0.2404 - val_loss: 1.6081 - val_accuracy: 0.2222\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.5353 - accuracy: 0.3462 - val_loss: 1.6135 - val_accuracy: 0.2222\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.5164 - accuracy: 0.3558 - val_loss: 1.6265 - val_accuracy: 0.1852\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.4922 - accuracy: 0.3942 - val_loss: 1.6447 - val_accuracy: 0.1481\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.4849 - accuracy: 0.3462 - val_loss: 1.6621 - val_accuracy: 0.1852\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.4889 - accuracy: 0.3558 - val_loss: 1.6689 - val_accuracy: 0.2222\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.4537 - accuracy: 0.3654 - val_loss: 1.6689 - val_accuracy: 0.2593\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.4811 - accuracy: 0.3173 - val_loss: 1.6503 - val_accuracy: 0.2593\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.4051 - accuracy: 0.4327 - val_loss: 1.6212 - val_accuracy: 0.2222\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.3942 - accuracy: 0.3750 - val_loss: 1.5904 - val_accuracy: 0.2222\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.3568 - accuracy: 0.5000 - val_loss: 1.5589 - val_accuracy: 0.2593\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.3465 - accuracy: 0.5000 - val_loss: 1.5274 - val_accuracy: 0.3333\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.3276 - accuracy: 0.5577 - val_loss: 1.4978 - val_accuracy: 0.3333\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.2740 - accuracy: 0.5673 - val_loss: 1.4754 - val_accuracy: 0.3333\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.2048 - accuracy: 0.6058 - val_loss: 1.4571 - val_accuracy: 0.4074\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1525 - accuracy: 0.5769 - val_loss: 1.4460 - val_accuracy: 0.4074\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1377 - accuracy: 0.5577 - val_loss: 1.4254 - val_accuracy: 0.3704\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1171 - accuracy: 0.5673 - val_loss: 1.3906 - val_accuracy: 0.3704\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.0253 - accuracy: 0.6058 - val_loss: 1.3590 - val_accuracy: 0.4444\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.0111 - accuracy: 0.6154 - val_loss: 1.3123 - val_accuracy: 0.4444\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0040 - accuracy: 0.6442 - val_loss: 1.2429 - val_accuracy: 0.3704\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.9304 - accuracy: 0.6923 - val_loss: 1.1970 - val_accuracy: 0.3704\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.8716 - accuracy: 0.6635 - val_loss: 1.2259 - val_accuracy: 0.4815\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.8735 - accuracy: 0.6731 - val_loss: 1.1321 - val_accuracy: 0.5185\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.8054 - accuracy: 0.6923 - val_loss: 1.0473 - val_accuracy: 0.5556\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7445 - accuracy: 0.7404 - val_loss: 1.0452 - val_accuracy: 0.5185\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6964 - accuracy: 0.7596 - val_loss: 1.1519 - val_accuracy: 0.5185\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7132 - accuracy: 0.7596 - val_loss: 1.0103 - val_accuracy: 0.5556\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6501 - accuracy: 0.7788 - val_loss: 0.9852 - val_accuracy: 0.5926\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6376 - accuracy: 0.7981 - val_loss: 0.9927 - val_accuracy: 0.5926\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5655 - accuracy: 0.7981 - val_loss: 1.0872 - val_accuracy: 0.5556\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5668 - accuracy: 0.7788 - val_loss: 1.1385 - val_accuracy: 0.5556\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5270 - accuracy: 0.8077 - val_loss: 1.1345 - val_accuracy: 0.5556\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5117 - accuracy: 0.8365 - val_loss: 1.0883 - val_accuracy: 0.5185\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4813 - accuracy: 0.8462 - val_loss: 1.0724 - val_accuracy: 0.5556\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4556 - accuracy: 0.8558 - val_loss: 1.1425 - val_accuracy: 0.5926\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4663 - accuracy: 0.8558 - val_loss: 1.0980 - val_accuracy: 0.5926\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3863 - accuracy: 0.8942 - val_loss: 1.1621 - val_accuracy: 0.5185\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4336 - accuracy: 0.8846 - val_loss: 1.1409 - val_accuracy: 0.5926\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4025 - accuracy: 0.8558 - val_loss: 1.2207 - val_accuracy: 0.6296\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3490 - accuracy: 0.9038 - val_loss: 1.3115 - val_accuracy: 0.4815\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3972 - accuracy: 0.8750 - val_loss: 1.3354 - val_accuracy: 0.5185\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.2850 - accuracy: 0.9038 - val_loss: 1.5157 - val_accuracy: 0.5185\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3145 - accuracy: 0.8750 - val_loss: 1.3269 - val_accuracy: 0.5926\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.2773 - accuracy: 0.9038 - val_loss: 1.0210 - val_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3192 - accuracy: 0.8942 - val_loss: 0.8987 - val_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2402 - accuracy: 0.9423 - val_loss: 0.9833 - val_accuracy: 0.7037\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.1868 - accuracy: 0.9615 - val_loss: 1.0936 - val_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2270 - accuracy: 0.9135 - val_loss: 1.0477 - val_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.1907 - accuracy: 0.9423 - val_loss: 1.0753 - val_accuracy: 0.6296\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2270 - accuracy: 0.9327 - val_loss: 1.1076 - val_accuracy: 0.6296\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1905 - accuracy: 0.9423 - val_loss: 1.1546 - val_accuracy: 0.6296\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.1721 - accuracy: 0.9519 - val_loss: 1.4046 - val_accuracy: 0.5926\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.1491 - accuracy: 0.9712 - val_loss: 1.4900 - val_accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.2633 - accuracy: 0.9038 - val_loss: 1.0579 - val_accuracy: 0.7037\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3030 - accuracy: 0.9038 - val_loss: 0.9611 - val_accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1323 - accuracy: 0.9519 - val_loss: 1.1808 - val_accuracy: 0.7407\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3124 - accuracy: 0.9135 - val_loss: 1.2602 - val_accuracy: 0.7778\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.1576 - accuracy: 0.9712 - val_loss: 1.2769 - val_accuracy: 0.7037\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1682 - accuracy: 0.9712 - val_loss: 1.1381 - val_accuracy: 0.6296\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.1687 - accuracy: 0.9327 - val_loss: 1.1141 - val_accuracy: 0.6296\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1158 - accuracy: 0.9615 - val_loss: 1.1602 - val_accuracy: 0.7037\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.1189 - accuracy: 0.9712 - val_loss: 1.3386 - val_accuracy: 0.6296\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1071 - accuracy: 0.9808 - val_loss: 1.2539 - val_accuracy: 0.7037\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.1219 - accuracy: 0.9808 - val_loss: 1.2597 - val_accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.1430 - accuracy: 0.9519 - val_loss: 1.1045 - val_accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.1234 - accuracy: 0.9519 - val_loss: 0.8843 - val_accuracy: 0.7407\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0808 - accuracy: 0.9712 - val_loss: 0.9339 - val_accuracy: 0.7407\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0879 - accuracy: 0.9904 - val_loss: 1.2005 - val_accuracy: 0.7037\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.1607 - accuracy: 0.9615 - val_loss: 1.1734 - val_accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.9931 - val_accuracy: 0.7037\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.1208 - accuracy: 0.9615 - val_loss: 1.0867 - val_accuracy: 0.7037\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.1215 - accuracy: 0.9423 - val_loss: 1.2856 - val_accuracy: 0.7037\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0698 - accuracy: 0.9808 - val_loss: 1.4476 - val_accuracy: 0.6296\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.1059 - accuracy: 0.9712 - val_loss: 1.3503 - val_accuracy: 0.6296\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0565 - accuracy: 0.9904 - val_loss: 1.0742 - val_accuracy: 0.7037\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0569 - accuracy: 0.9808 - val_loss: 0.9795 - val_accuracy: 0.7037\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0732 - accuracy: 0.9808 - val_loss: 1.0077 - val_accuracy: 0.6667\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0703 - accuracy: 0.9808 - val_loss: 1.2103 - val_accuracy: 0.5926\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0763 - accuracy: 0.9808 - val_loss: 1.3782 - val_accuracy: 0.6296\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 1.4390 - val_accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 1.4357 - val_accuracy: 0.6296\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 1.3994 - val_accuracy: 0.5926\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 1.3900 - val_accuracy: 0.5926\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 1.4161 - val_accuracy: 0.6296\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.4219 - val_accuracy: 0.6667\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0381 - accuracy: 0.9904 - val_loss: 1.4344 - val_accuracy: 0.6667\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.4212 - val_accuracy: 0.6667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.3562 - val_accuracy: 0.6667\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.3017 - val_accuracy: 0.7037\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.2969 - val_accuracy: 0.7037\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 1.2776 - val_accuracy: 0.7407\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0322 - accuracy: 0.9904 - val_loss: 1.3026 - val_accuracy: 0.6296\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.3595 - val_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.3852 - val_accuracy: 0.6667\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.3552 - val_accuracy: 0.5926\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0254 - accuracy: 0.9904 - val_loss: 1.1875 - val_accuracy: 0.7037\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.1135 - val_accuracy: 0.7407\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0378 - accuracy: 0.9808 - val_loss: 1.1240 - val_accuracy: 0.7407\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(embeddings_matrix_train, Y_train, epochs=100, batch_size=64, shuffle=True, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001799046AE60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 9ms/step\n",
      "[4 3 2 2 2 2 3 2 4 2 1 2 0 3 1 3 2 0 3 4 0 3 2 2 3 3 2 0 1 2 0 1 3 2 3 2 2\n",
      " 3 4 2 1 0 0 2 2 2 2 2 3 3 3 4 3 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(embeddings_matrix_test)\n",
    "predicted_classes = np.argmax(pred, axis=1)\n",
    "print(predicted_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 2.6487 - accuracy: 0.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6486871242523193, 0.5714285969734192]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(embeddings_matrix_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\n",
      "actual label - üç¥\n",
      "predicted label - üç¥\n",
      "\n",
      "he did not answer\n",
      "actual label - üòû\n",
      "predicted label - üòû\n",
      "\n",
      "he got a raise\n",
      "actual label - üòÉ\n",
      "predicted label - üòÉ\n",
      "\n",
      "she got me a present\n",
      "actual label - ‚ù§Ô∏è\n",
      "predicted label - üòÉ\n",
      "\n",
      "ha ha ha it was so funny\n",
      "actual label - üòÉ\n",
      "predicted label - üòÉ\n",
      "\n",
      "he is a good friend\n",
      "actual label - ‚ù§Ô∏è\n",
      "predicted label - üòÉ\n",
      "\n",
      "I am upset\n",
      "actual label - ‚ù§Ô∏è\n",
      "predicted label - üòû\n",
      "\n",
      "We had such a lovely dinner tonight\n",
      "actual label - ‚ù§Ô∏è\n",
      "predicted label - üòÉ\n",
      "\n",
      "where is the food\n",
      "actual label - üç¥\n",
      "predicted label - üç¥\n",
      "\n",
      "Stop making this joke ha ha ha\n",
      "actual label - üòÉ\n",
      "predicted label - üòÉ\n",
      "\n",
      "where is the ball\n",
      "actual label - ‚öæ\n",
      "predicted label - ‚öæ\n",
      "\n",
      "work is hard\n",
      "actual label - üòû\n",
      "predicted label - üòÉ\n",
      "\n",
      "This girl is messing with me\n",
      "actual label - üòû\n",
      "predicted label - ‚ù§Ô∏è\n",
      "\n",
      "are you serious ha ha\n",
      "actual label - üòÉ\n",
      "predicted label - üòû\n",
      "\n",
      "Let us go play baseball\n",
      "actual label - ‚öæ\n",
      "predicted label - ‚öæ\n",
      "\n",
      "This stupid grader is not working\n",
      "actual label - üòû\n",
      "predicted label - üòû\n",
      "\n",
      "work is horrible\n",
      "actual label - üòû\n",
      "predicted label - üòÉ\n",
      "\n",
      "Congratulation for having a baby\n",
      "actual label - üòÉ\n",
      "predicted label - ‚ù§Ô∏è\n",
      "\n",
      "stop messing around\n",
      "actual label - üòû\n",
      "predicted label - üòû\n",
      "\n",
      "any suggestions for dinner\n",
      "actual label - üç¥\n",
      "predicted label - üç¥\n",
      "\n",
      "I love taking breaks\n",
      "actual label - ‚ù§Ô∏è\n",
      "predicted label - ‚ù§Ô∏è\n",
      "\n",
      "you brighten my day\n",
      "actual label - üòÉ\n",
      "predicted label - üòû\n",
      "\n",
      "I boiled rice\n",
      "actual label - üç¥\n",
      "predicted label - üòÉ\n",
      "\n",
      "she is a bully\n",
      "actual label - üòû\n",
      "predicted label - üòÉ\n",
      "\n",
      "Why are you feeling bad\n",
      "actual label - üòû\n",
      "predicted label - üòû\n",
      "\n",
      "I am upset\n",
      "actual label - üòû\n",
      "predicted label - üòû\n",
      "\n",
      "I worked during my birthday\n",
      "actual label - üòû\n",
      "predicted label - üòÉ\n",
      "\n",
      "My grandmother is the love of my life\n",
      "actual label - ‚ù§Ô∏è\n",
      "predicted label - ‚ù§Ô∏è\n",
      "\n",
      "enjoy your break\n",
      "actual label - üòÉ\n",
      "predicted label - ‚öæ\n",
      "\n",
      "valentine day is near\n",
      "actual label - ‚ù§Ô∏è\n",
      "predicted label - üòÉ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(\" \".join(X_test[i]))\n",
    "    print(\"actual label -\", emoji.emojize(emoji_dictionary[str(Y_test[i].argmax())]))\n",
    "    print(\"predicted label -\", emoji.emojize(emoji_dictionary[str(pred[i].argmax())]))\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
